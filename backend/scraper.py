#!/usr/bin/env python3
"""
LCSC ç”µå­å…ƒå™¨ä»¶çˆ¬è™«
å®šæ—¶ä» LCSC æŠ“å–å™¨ä»¶æ•°æ®ï¼Œæä¾›å®æ—¶ä»·æ ¼å’Œåº“å­˜æŸ¥è¯¢
"""

import requests
from bs4 import BeautifulSoup
import json
import time
import re
from datetime import datetime
from urllib.parse import quote

# é…ç½®
BASE_URL = "https://www.lcsc.com"
SEARCH_URL = f"{BASE_URL}/search"
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
    "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
    "Accept-Encoding": "gzip, deflate, br",
    "Connection": "keep-alive",
}

# çƒ­é—¨æœç´¢åˆ—è¡¨
POPULAR_PARTS = [
    "STM32F103C8T6",
    "GD32F103C8T6",
    "ESP32-WROOM-32",
    "ESP32-C3FH4",
    "CH340N",
    "CH340G",
    "LD1117V33",
    "AMS1117-3.3",
    "LM358",
    "SGM358",
    "AO3400",
    "2N7000",
    "IRF540N",
    "NE555",
    "ATMEGA328P",
    "74HC595",
    "74HC04",
    "MAX232",
    "LM317",
    "AMS1117",
]


def search_lcsc(keyword):
    """
    æœç´¢ LCSC è·å–å™¨ä»¶ä¿¡æ¯
    """
    try:
        encoded_keyword = quote(keyword, safe='')
        url = f"{SEARCH_URL}?q={encoded_keyword}"
        
        print(f"ğŸ” æ­£åœ¨æœç´¢: {keyword}...")
        
        response = requests.get(url, headers=HEADERS, timeout=30)
        
        if response.status_code != 200:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {response.status_code}")
            return []
        
        # è§£ææœç´¢ç»“æœ
        soup = BeautifulSoup(response.text, 'lxml')
        results = []
        
        # æŸ¥æ‰¾äº§å“åˆ—è¡¨ - LCSC çš„ç»“æ„å¯èƒ½å˜åŒ–
        product_cards = soup.find_all('div', class_='search-product-list') or \
                       soup.find_all('div', class_='product-list') or \
                       soup.find_all('div', class_='goods-list')
        
        if not product_cards:
            # å¤‡é€‰æ–¹æ¡ˆï¼šæŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„äº§å“å®¹å™¨
            product_cards = soup.find_all('div', class_=re.compile(r'product|goods|item'))
        
        for card in product_cards[:10]:  # æœ€å¤šå– 10 ä¸ªç»“æœ
            try:
                part_info = extract_product_info(card)
                if part_info:
                    results.append(part_info)
            except Exception as e:
                continue
        
        print(f"âœ… æ‰¾åˆ° {len(results)} ä¸ªç»“æœ")
        return results
        
    except Exception as e:
        print(f"âŒ æœç´¢å‡ºé”™: {e}")
        return []


def extract_product_info(card):
    """
    ä»äº§å“å¡ç‰‡ä¸­æå–ä¿¡æ¯
    """
    try:
        # å°è¯•å¤šç§é€‰æ‹©å™¨
        selectors = [
            ('a', 'product-name'),
            ('a', 'goods-name'),
            ('a', 'name'),
            ('a', 'product-title'),
        ]
        
        name_elem = None
        for tag, cls in selectors:
            elem = card.find(tag, class_=re.compile(cls))
            if elem:
                name_elem = elem
                break
        
        if not name_elem:
            # æŸ¥æ‰¾ä»»ä½•é“¾æ¥
            name_elem = card.find('a')
        
        name = name_elem.get_text(strip=True) if name_elem else ""
        
        # æå–ä»·æ ¼
        price_elem = card.find(class_=re.compile(r'price|current-price'))
        price = ""
        if price_elem:
            price = price_elem.get_text(strip=True)
        
        # æå–åº“å­˜
        stock_elem = card.find(class_=re.compile(r'stock|inventory'))
        stock = ""
        if stock_elem:
            stock = stock_elem.get_text(strip=True)
        
        # æå–å‹å·
        part_elem = card.find(class_=re.compile(r'model|part-number'))
        part = ""
        if part_elem:
            part = part_elem.get_text(strip=True)
        
        if not part and name:
            part = name.split()[0] if name.split() else name
        
        # æå–é“¾æ¥
        link = ""
        if name_elem and name_elem.get('href'):
            link = name_elem['href']
            if not link.startswith('http'):
                link = BASE_URL + link
        
        return {
            "part": part or "Unknown",
            "name": name or "",
            "price": price,
            "stock": stock,
            "link": link,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        return None


def get_product_detail(url):
    """
    è·å–äº§å“è¯¦æƒ…é¡µ
    """
    try:
        response = requests.get(url, headers=HEADERS, timeout=30)
        
        if response.status_code != 200:
            return None
        
        soup = BeautifulSoup(response.text, 'lxml')
        
        # æå–è¯¦æƒ…
        data = {}
        
        # åˆ¶é€ å•†
        mfr_elem = soup.find(class_=re.compile(r'manufacturer|mfr'))
        if mfr_elem:
            data['manufacturer'] = mfr_elem.get_text(strip=True)
        
        # æè¿°
        desc_elem = soup.find(class_=re.compile(r'description|detail-desc'))
        if desc_elem:
            data['description'] = desc_elem.get_text(strip=True)[:200]
        
        # å°è£…
        pkg_elem = soup.find(class_=re.compile(r'package|footprint'))
        if pkg_elem:
            data['package'] = pkg_elem.get_text(strip=True)
        
        # ä»·æ ¼åŒºé—´
        price_table = soup.find('table', class_=re.compile(r'price-table'))
        if price_table:
            prices = []
            for row in price_table.find_all('tr'):
                cells = row.find_all(['td', 'th'])
                if len(cells) >= 2:
                    qty = cells[0].get_text(strip=True)
                    price = cells[1].get_text(strip=True)
                    prices.append({"qty": qty, "price": price})
            data['pricing'] = prices
        
        return data
        
    except Exception as e:
        print(f"âŒ è·å–è¯¦æƒ…å¤±è´¥: {e}")
        return None


def scrape_all_popular():
    """
    çˆ¬å–æ‰€æœ‰çƒ­é—¨å™¨ä»¶
    """
    print("=" * 60)
    print("ğŸ¤– LCSC ç”µå­å…ƒå™¨ä»¶æ•°æ®çˆ¬è™«")
    print("=" * 60)
    print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().isoformat()}")
    print(f"ğŸ“¦ å°†çˆ¬å– {len(POPULAR_PARTS)} ä¸ªçƒ­é—¨å™¨ä»¶")
    print("=" * 60)
    
    all_data = {
        "meta": {
            "updated": datetime.now().isoformat(),
            "source": "LCSC (ç«‹åˆ›å•†åŸ)",
            "version": "1.0.0",
            "part_count": len(POPULAR_PARTS)
        },
        "parts": []
    }
    
    for i, part in enumerate(POPULAR_PARTS, 1):
        print(f"\n[{i}/{len(POPULAR_PARTS)}] ", end="")
        
        # æœç´¢è·å–åŸºæœ¬ä¿¡æ¯
        results = search_lcsc(part)
        
        if results:
            # å–ç¬¬ä¸€ä¸ªç»“æœä½œä¸ºä¸»è¦ä¿¡æ¯
            main_result = results[0]
            
            # å¦‚æœæœ‰è¯¦æƒ…é¡µé“¾æ¥ï¼Œè·å–æ›´å¤šä¿¡æ¯
            if main_result.get('link'):
                detail = get_product_detail(main_result['link'])
                if detail:
                    main_result.update(detail)
            
            all_data['parts'].append(main_result)
        else:
            # æœç´¢å¤±è´¥ï¼Œæ·»åŠ å ä½æ•°æ®
            all_data['parts'].append({
                "part": part,
                "name": part,
                "price": "æŸ¥è¯¢ä¸­",
                "stock": "æŸ¥è¯¢ä¸­",
                "link": f"{SEARCH_URL}?q={quote(part)}",
                "timestamp": datetime.now().isoformat(),
                "status": "not_found"
            })
        
        # ç¤¼è²Œæ€§å»¶è¿Ÿ
        time.sleep(1)
    
    print("\n" + "=" * 60)
    print(f"âœ… çˆ¬å–å®Œæˆ! å…±è·å– {len(all_data['parts'])} ä¸ªå™¨ä»¶")
    print(f"â° ç»“æŸæ—¶é—´: {datetime.now().isoformat()}")
    print("=" * 60)
    
    return all_data


def save_to_json(data, filename="parts.json"):
    """
    ä¿å­˜æ•°æ®åˆ° JSON æ–‡ä»¶
    """
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {filename}")


def main():
    """
    ä¸»å‡½æ•°
    """
    # çˆ¬å–æ•°æ®
    data = scrape_all_popular()
    
    # ä¿å­˜æ•°æ®
    save_to_json(data, "../data/parts.json")
    
    # åŒæ—¶ä¿å­˜ä¸€ä»½å¸¦æ—¶é—´æˆ³çš„ç‰ˆæœ¬
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    save_to_json(data, f"../data/parts_{timestamp}.json")
    
    print("\nğŸ“‹ çˆ¬å–æ‘˜è¦:")
    for part in data['parts']:
        status = "âœ…" if part.get('status') != 'not_found' else "âš ï¸"
        print(f"  {status} {part['part']}: {part['price']} | {part['stock']}")


if __name__ == "__main__":
    main()
